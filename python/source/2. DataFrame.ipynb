{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbbb8756-c3e0-429e-818d-6c1f6cc0e5d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45d2c8d-9331-48bd-b5c2-df4c1829fe6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crear schema\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "schema = StructType([\n",
    "  StructField('firstname', StringType(), True),\n",
    "  StructField('middlename', StringType(), True),\n",
    "  StructField('lastname', StringType(), True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95196dd0-af37-4333-a104-5ebb6f574377",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "#Crear un RDD vacio\n",
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "print(emptyRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0ab1c1-58f2-4e14-a477-d521a1e99e89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Crear un DataFrame desde un RDD vacio\n",
    "df = spark.createDataFrame(emptyRDD,schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17811ac1-572c-4d13-8be6-b4f76c578674",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#Convertir RDD a DataFrame utilizando toDF\n",
    "df1 = emptyRDD.toDF(schema)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b7d42fb-3f69-4d4b-ae92-1995abc7bc60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creacion de DF desde un RDD\nroot\n |-- _1: string (nullable = true)\n |-- _2: long (nullable = true)\n\n+---------+---+\n|_1       |_2 |\n+---------+---+\n|Finance  |10 |\n|Marketing|20 |\n|Sales    |30 |\n|IT       |40 |\n+---------+---+\n\nCreacion de DF desde un RDD con las columnas\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\nCreacion de DF utilizando createDataFrame\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\nCreacion de DF utilizando createDataFrame y un schema\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: string (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "rdd = spark.sparkContext.parallelize(dept)\n",
    "\n",
    "print(\"Creacion de DF desde un RDD\")\n",
    "df = rdd.toDF()\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "print(\"Creacion de DF desde un RDD con las columnas\")\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "df2 = rdd.toDF(deptColumns)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "print(\"Creacion de DF utilizando createDataFrame\")\n",
    "deptDF = spark.createDataFrame(rdd, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)\n",
    "\n",
    "\n",
    "print(\"Creacion de DF utilizando createDataFrame y un schema\")\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "deptSchema = StructType([       \n",
    "    StructField('dept_name', StringType(), True),\n",
    "    StructField('dept_id', StringType(), True)\n",
    "])\n",
    "\n",
    "deptDF1 = spark.createDataFrame(rdd, schema = deptSchema)\n",
    "deptDF1.printSchema()\n",
    "deptDF1.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6041b73-a4af-4d9e-8ba3-f2eac4bcad69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creacion de dataframe con columnas simple\nCreacion de dataframe con columnas anidadas\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>firstname</th><th>middlename</th><th>lastname</th><th>id</th><th>gender</th><th>salary</th></tr></thead><tbody><tr><td>James</td><td></td><td>Smith</td><td>36636</td><td>M</td><td>3000</td></tr><tr><td>Michael</td><td>Rose</td><td></td><td>40288</td><td>M</td><td>4000</td></tr><tr><td>Robert</td><td></td><td>Williams</td><td>42114</td><td>M</td><td>4000</td></tr><tr><td>Maria</td><td>Anne</td><td>Jones</td><td>39192</td><td>F</td><td>4000</td></tr><tr><td>Jen</td><td>Mary</td><td>Brown</td><td></td><td>F</td><td>-1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "James",
         "",
         "Smith",
         "36636",
         "M",
         3000
        ],
        [
         "Michael",
         "Rose",
         "",
         "40288",
         "M",
         4000
        ],
        [
         "Robert",
         "",
         "Williams",
         "42114",
         "M",
         4000
        ],
        [
         "Maria",
         "Anne",
         "Jones",
         "39192",
         "F",
         4000
        ],
        [
         "Jen",
         "Mary",
         "Brown",
         "",
         "F",
         -1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "middlename",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>id</th><th>gender</th><th>salary</th></tr></thead><tbody><tr><td>List(James, , Smith)</td><td>36636</td><td>M</td><td>3100</td></tr><tr><td>List(Michael, Rose, )</td><td>40288</td><td>M</td><td>4300</td></tr><tr><td>List(Robert, , Williams)</td><td>42114</td><td>M</td><td>1400</td></tr><tr><td>List(Maria, Anne, Jones)</td><td>39192</td><td>F</td><td>5500</td></tr><tr><td>List(Jen, Mary, Brown)</td><td></td><td>F</td><td>-1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "James",
          "",
          "Smith"
         ],
         "36636",
         "M",
         3100
        ],
        [
         [
          "Michael",
          "Rose",
          ""
         ],
         "40288",
         "M",
         4300
        ],
        [
         [
          "Robert",
          "",
          "Williams"
         ],
         "42114",
         "M",
         1400
        ],
        [
         [
          "Maria",
          "Anne",
          "Jones"
         ],
         "39192",
         "F",
         5500
        ],
        [
         [
          "Jen",
          "Mary",
          "Brown"
         ],
         "",
         "F",
         -1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"firstname\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"middlename\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"lastname\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>OtherInfo</th></tr></thead><tbody><tr><td>List(James, , Smith)</td><td>List(36636, M, 3100, Medium)</td></tr><tr><td>List(Michael, Rose, )</td><td>List(40288, M, 4300, High)</td></tr><tr><td>List(Robert, , Williams)</td><td>List(42114, M, 1400, Low)</td></tr><tr><td>List(Maria, Anne, Jones)</td><td>List(39192, F, 5500, High)</td></tr><tr><td>List(Jen, Mary, Brown)</td><td>List(, F, -1, Low)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "James",
          "",
          "Smith"
         ],
         [
          "36636",
          "M",
          3100,
          "Medium"
         ]
        ],
        [
         [
          "Michael",
          "Rose",
          ""
         ],
         [
          "40288",
          "M",
          4300,
          "High"
         ]
        ],
        [
         [
          "Robert",
          "",
          "Williams"
         ],
         [
          "42114",
          "M",
          1400,
          "Low"
         ]
        ],
        [
         [
          "Maria",
          "Anne",
          "Jones"
         ],
         [
          "39192",
          "F",
          5500,
          "High"
         ]
        ],
        [
         [
          "Jen",
          "Mary",
          "Brown"
         ],
         [
          "",
          "F",
          -1,
          "Low"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"firstname\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"middlename\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"lastname\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "OtherInfo",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"identifier\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"salary\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Salary_Grade\",\"type\":\"string\",\"nullable\":false,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,MapType\n",
    "from pyspark.sql.functions import col,struct,when\n",
    "\n",
    "\n",
    "\n",
    "print(\"Creacion de dataframe con columnas simple\")\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \n",
    "    StructField(\"firstname\",StringType(),True), \n",
    "    StructField(\"middlename\",StringType(),True), \n",
    "    StructField(\"lastname\",StringType(),True), \n",
    "    StructField(\"id\", StringType(), True), \n",
    "    StructField(\"gender\", StringType(), True), \n",
    "    StructField(\"salary\", IntegerType(), True) \n",
    "  ])\n",
    "\n",
    "print(\"Creacion de dataframe con columnas anidadas\")\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "#df.show(truncate=False)\n",
    "display(df)\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "\n",
    "#df2.show(truncate=False)\n",
    "display(df2)\n",
    "\n",
    "\n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "    struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "#updatedDF.show(truncate=False)\n",
    "display(updatedDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b510766a-6780-4dc5-a6d6-f348b40b890d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creacion del dataframe\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|James    |Smith   |USA    |CA   |\n|Michael  |Rose    |USA    |NY   |\n|Robert   |Williams|USA    |CA   |\n|Maria    |Jones   |USA    |FL   |\n+---------+--------+-------+-----+\n\n+---------+\n|firstname|\n+---------+\n|    James|\n|  Michael|\n|   Robert|\n|    Maria|\n+---------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+-----+------+\n|name                  |state|gender|\n+----------------------+-----+------+\n|{James, null, Smith}  |OH   |M     |\n|{Anna, Rose, }        |NY   |F     |\n|{Julia, , Williams}   |OH   |F     |\n|{Maria, Anne, Jones}  |NY   |M     |\n|{Jen, Mary, Brown}    |NY   |M     |\n|{Mike, Mary, Williams}|OH   |M     |\n+----------------------+-----+------+\n\n+----------------------+\n|name                  |\n+----------------------+\n|{James, null, Smith}  |\n|{Anna, Rose, }        |\n|{Julia, , Williams}   |\n|{Maria, Anne, Jones}  |\n|{Jen, Mary, Brown}    |\n|{Mike, Mary, Williams}|\n+----------------------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|James    |Smith   |\n|Anna     |        |\n|Julia    |Williams|\n|Maria    |Jones   |\n|Jen      |Brown   |\n|Mike     |Williams|\n+---------+--------+\n\n+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|James    |null      |Smith   |\n|Anna     |Rose      |        |\n|Julia    |          |Williams|\n|Maria    |Anne      |Jones   |\n|Jen      |Mary      |Brown   |\n|Mike     |Mary      |Williams|\n+---------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "print(\"creacion del dataframe\")\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.select(\"firstname\").show()\n",
    "\n",
    "df.select(\"firstname\",\"lastname\").show()\n",
    "\n",
    "#Using Dataframe object name\n",
    "df.select(df.firstname,df.lastname).show()\n",
    "\n",
    "# Using col function\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"),col(\"lastname\")).show()\n",
    "\n",
    "data = [((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False) # shows all columns\n",
    "\n",
    "df2.select(\"name\").show(truncate=False)\n",
    "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)\n",
    "df2.select(\"name.*\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e3f2508-8a3d-4f1e-b1c8-ab1311c139a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |300000|\n|Michael  |Rose      |        |2000-05-19|M     |400000|\n|Robert   |          |Williams|1978-09-05|M     |400000|\n|Maria    |Anne      |Jones   |1967-12-01|F     |400000|\n|Jen      |Mary      |Brown   |1980-02-17|F     |-100  |\n+---------+----------+--------+----------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- CopiedColumn: long (nullable = true)\n\n+---------+----------+--------+----------+------+------+------------+\n|firstname|middlename|lastname|       dob|gender|salary|CopiedColumn|\n+---------+----------+--------+----------+------+------+------------+\n|    James|          |   Smith|1991-04-01|     M|  3000|       -3000|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|       -4000|\n|   Robert|          |Williams|1978-09-05|     M|  4000|       -4000|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|       -4000|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|           1|\n+---------+----------+--------+----------+------+------+------------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- Country: string (nullable = false)\n\nroot\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- Country: string (nullable = false)\n |-- anotherColumn: string (nullable = false)\n\n+---------+----------+--------+----------+------+------+-------+-------------+\n|firstname|middlename|lastname|       dob|gender|salary|Country|anotherColumn|\n+---------+----------+--------+----------+------+------+-------+-------------+\n|    James|          |   Smith|1991-04-01|     M|  3000|    USA| anotherValue|\n|  Michael|      Rose|        |2000-05-19|     M|  4000|    USA| anotherValue|\n|   Robert|          |Williams|1978-09-05|     M|  4000|    USA| anotherValue|\n|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|    USA| anotherValue|\n|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|    USA| anotherValue|\n+---------+----------+--------+----------+------+------+-------+-------------+\n\n+---------+----------+--------+----------+---+------+\n|firstname|middlename|lastname|dob       |sex|salary|\n+---------+----------+--------+----------+---+------+\n|James    |          |Smith   |1991-04-01|M  |3000  |\n|Michael  |Rose      |        |2000-05-19|M  |4000  |\n|Robert   |          |Williams|1978-09-05|M  |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n+---------+----------+--------+----------+---+------+\n\n+---------+----------+--------+----------+------+------+\n|firstname|middlename|lastname|dob       |gender|salary|\n+---------+----------+--------+----------+------+------+\n|James    |          |Smith   |1991-04-01|M     |3000  |\n|Michael  |Rose      |        |2000-05-19|M     |4000  |\n|Robert   |          |Williams|1978-09-05|M     |4000  |\n|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n+---------+----------+--------+----------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df2 = df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\"))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "df3 = df.withColumn(\"salary\",col(\"salary\")*100)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False) \n",
    "\n",
    "df4 = df.withColumn(\"CopiedColumn\",col(\"salary\")* -1)\n",
    "df4.printSchema()\n",
    "df4.show()\n",
    "\n",
    "df5 = df.withColumn(\"Country\", lit(\"USA\")) # df[\"camponuevo\"] = 2\n",
    "df5.printSchema()\n",
    "\n",
    "df6 = df.withColumn(\"Country\", lit(\"USA\")) \\\n",
    "   .withColumn(\"anotherColumn\",lit(\"anotherValue\"))\n",
    "df6.printSchema()\n",
    "df6.show()\n",
    "\n",
    "df.withColumnRenamed(\"gender\",\"sex\") \\\n",
    "  .show(truncate=False) \n",
    "  \n",
    "df4.drop(\"CopiedColumn\") \\\n",
    ".show(truncate=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fd5bc6-37b0-4138-b1c2-e71f666d746a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }        |[Spark, Java, C++]|NY   |F     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------------+------------------+-----+------+\n|name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n+----------------+------------------+-----+------+\n|name            |languages         |state|gender|\n+----------------+------------------+-----+------+\n|{James, , Smith}|[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }  |[Spark, Java, C++]|NY   |F     |\n+----------------+------------------+-----+------+\n\n+----------------------+------------+-----+------+\n|name                  |languages   |state|gender|\n+----------------------+------------+-----+------+\n|{Julia, , Williams}   |[CSharp, VB]|OH   |F     |\n|{Mike, Mary, Williams}|[Python, VB]|OH   |M     |\n+----------------------+------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,array_contains\n",
    "\n",
    "arrayStructureData = [\n",
    "        ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    "        ]\n",
    "        \n",
    "arrayStructureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('languages', ArrayType(StringType()), True),\n",
    "         StructField('state', StringType(), True),\n",
    "         StructField('gender', StringType(), True)\n",
    "         ])\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data = arrayStructureData, schema = arrayStructureSchema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.filter(df.state == \"OH\") \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "df.filter(col(\"state\") == \"OH\") \\\n",
    "    .show(truncate=False)    \n",
    "    \n",
    "df.filter(\"gender  == 'M'\") \\\n",
    "    .show(truncate=False)    \n",
    "\n",
    "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)        \n",
    "\n",
    "df.filter(array_contains(df.languages,\"Java\")) \\\n",
    "    .show(truncate=False)        \n",
    "\n",
    "df.filter(df.name.lastname == \"Williams\") \\\n",
    "    .show(truncate=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca13733-bf94-4f3e-af15-ed152287430e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|James        |Sales     |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count: 9\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count: 9\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\nDistinct count of department salary : 8\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|Maria        |Finance   |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Kumar        |Marketing |2000  |\n|Jeff         |Marketing |3000  |\n|James        |Sales     |3000  |\n|Robert       |Sales     |4100  |\n|Michael      |Sales     |4600  |\n+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "#Distinct\n",
    "distinctDF = df.distinct()\n",
    "print(\"Distinct count: \"+str(distinctDF.count()))\n",
    "distinctDF.show(truncate=False)\n",
    "\n",
    "#Drop duplicates\n",
    "df2 = df.dropDuplicates()\n",
    "print(\"Distinct count: \"+str(df2.count()))\n",
    "df2.show(truncate=False)\n",
    "\n",
    "#Drop duplicates on selected columns\n",
    "dropDisDF = df.dropDuplicates([\"department\",\"salary\"])\n",
    "print(\"Distinct count of department salary : \"+str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce08125-ea3a-411d-a131-a24a258f5dfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>salary</th></tr></thead><tbody><tr><td>Maria</td><td>Finance</td><td>3000</td></tr><tr><td>Jeff</td><td>Marketing</td><td>3000</td></tr><tr><td>James</td><td>Sales</td><td>3000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Maria",
         "Finance",
         3000
        ],
        [
         "Jeff",
         "Marketing",
         3000
        ],
        [
         "James",
         "Sales",
         3000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropDisDF = df.dropDuplicates(subset=[\"department\"])\n",
    "display(dropDisDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d20ef6-054e-4f1f-a157-8c91d3c9b801",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n+-------------+----------+-----+------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, asc,desc\n",
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.sort(\"department\",\"state\").show(truncate=False)\n",
    "df.sort(col(\"department\"),col(\"state\")).show(truncate=False)\n",
    "\n",
    "df.orderBy(\"department\",\"state\").show(truncate=False)\n",
    "df.orderBy(col(\"department\"),col(\"state\")).show(truncate=False)\n",
    "\n",
    "df.sort(df.department.asc(),df.state.asc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "\n",
    "df.sort(df.department.asc(),df.state.desc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select employee_name,department,state,salary,age,bonus from EMP ORDER BY department asc\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a481ae3-5ebf-4228-bd38-b5c61888655b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|Sales     |257000     |\n|Finance   |351000     |\n|Marketing |171000     |\n+----------+-----------+\n\n+----------+-----+\n|department|count|\n+----------+-----+\n|Sales     |3    |\n|Finance   |4    |\n|Marketing |2    |\n+----------+-----+\n\n+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|Sales     |NY   |176000     |30000     |\n|Sales     |CA   |81000      |23000     |\n|Finance   |CA   |189000     |47000     |\n|Finance   |NY   |162000     |34000     |\n|Marketing |NY   |91000      |21000     |\n|Marketing |CA   |80000      |18000     |\n+----------+-----+-----------+----------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n|Marketing |171000    |85500.0          |39000    |21000    |\n+----------+----------+-----------------+---------+---------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n+----------+----------+-----------------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,sum,avg,max\n",
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.groupBy(\"department\").sum(\"salary\").show(truncate=False)\n",
    "\n",
    "df.groupBy(\"department\").count().show(truncate=False)\n",
    "\n",
    "\n",
    "(df.groupBy(\"department\",\"state\") \n",
    "   .sum(\"salary\",\"bonus\") \n",
    "   .show(truncate=False))\n",
    "\n",
    "(df.groupBy(\"department\") \n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \n",
    "         avg(\"salary\").alias(\"avg_salary\"), \n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \n",
    "         max(\"bonus\").alias(\"max_bonus\") \n",
    "     ) \n",
    "    .show(truncate=False))\n",
    "    \n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "\n",
    "# select sum(), avg(), sum, max() from tabla where sum_bonus >= 50000 group by department\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3c0759-c307-4092-880e-2bb14ec14782",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- emp_id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- superior_emp_id: long (nullable = true)\n |-- year_joined: string (nullable = true)\n |-- emp_dept_id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+------+--------+---------------+-----------+-----------+------+------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+--------+---------------+-----------+-----------+------+------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |\n|2     |Rose    |1              |2010       |20         |M     |4000  |\n|3     |Williams|1              |2010       |10         |M     |1000  |\n|4     |Jones   |2              |2005       |10         |F     |2000  |\n|5     |Brown   |2              |2010       |40         |      |-1    |\n|6     |Brown   |2              |2010       |50         |      |-1    |\n+------+--------+---------------+-----------+-----------+------+------+\n\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+--------+---------------+-----------+-----------+------+------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |\n|3     |Williams|1              |2010       |10         |M     |1000  |\n|4     |Jones   |2              |2005       |10         |F     |2000  |\n|2     |Rose    |1              |2010       |20         |M     |4000  |\n|5     |Brown   |2              |2010       |40         |      |-1    |\n+------+--------+---------------+-----------+-----------+------+------+\n\n+------+-----+---------------+-----------+-----------+------+------+\n|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n+------+-----+---------------+-----------+-----------+------+------+\n|6     |Brown|2              |2010       |50         |      |-1    |\n+------+-----+---------------+-----------+-----------+------+------+\n\n+------+--------+---------------+-----------------+\n|emp_id|name    |superior_emp_id|superior_emp_name|\n+------+--------+---------------+-----------------+\n|2     |Rose    |1              |Smith            |\n|3     |Williams|1              |Smith            |\n|4     |Jones   |2              |Rose             |\n|5     |Brown   |2              |Rose             |\n|6     |Brown   |2              |Rose             |\n+------+--------+---------------+-----------------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "\n",
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40) \\\n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)\n",
    "  \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") \\\n",
    "     .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\") \\\n",
    "    .show(truncate=False)\n",
    "    \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\") \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\") \\\n",
    "   .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\") \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\") \\\n",
    "   .show(truncate=False)\n",
    "   \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\") \\\n",
    "   .show(truncate=False)\n",
    "   \n",
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), \\\n",
    "    col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\") \\\n",
    "    .select(col(\"emp1.emp_id\"),col(\"emp1.name\"), \\\n",
    "      col(\"emp2.emp_id\").alias(\"superior_emp_id\"), \\\n",
    "      col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "empDF.createOrReplaceTempView(\"EMP\")\n",
    "deptDF.createOrReplaceTempView(\"DEPT\")\n",
    "   \n",
    "joinDF = spark.sql(\"select * from EMP e, DEPT d where e.emp_dept_id == d.dept_id\") \\\n",
    "  .show(truncate=False)\n",
    "\n",
    "joinDF2 = spark.sql(\"select * from EMP e INNER JOIN DEPT d ON e.emp_dept_id == d.dept_id\") \\\n",
    "  .show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4312e2e1-d3ed-46e4-bcce-d97d043acb3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n+-------------+----------+-----+------+---+-----+\n\nroot\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|James        |Sales     |NY   |90000 |34 |10000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000) \\\n",
    "  ]\n",
    "\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "simpleData2 = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns2= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data = simpleData2, schema = columns2)\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "unionDF = df.union(df2)\n",
    "unionDF.show(truncate=False)\n",
    "disDF = df.union(df2).distinct()\n",
    "disDF.show(truncate=False)\n",
    "\n",
    "unionAllDF = df.unionAll(df2)\n",
    "unionAllDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2e6f0d-6a88-452a-88ca-486e13167657",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- zipcode: integer (nullable = true)\n |-- type: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- population: integer (nullable = true)\n\n+---+-------+--------+-------------------+-----+----------+\n|id |zipcode|type    |city               |state|population|\n+---+-------+--------+-------------------+-----+----------+\n|1  |704    |STANDARD|null               |PR   |30100     |\n|2  |704    |null    |PASEO COSTA DEL SUR|PR   |null      |\n|3  |709    |null    |BDA SAN LUIS       |PR   |3700      |\n|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n|5  |76177  |STANDARD|null               |TX   |null      |\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|               null|   PR|     30100|\n|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|               null|   TX|         0|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|               null|   PR|     30100|\n|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|               null|   TX|         0|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|               null|   PR|     30100|\n|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|               null|   TX|         0|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|               null|   PR|     30100|\n|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|               null|   TX|         0|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|                   |   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|                   |   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|                   |   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|                   |   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|            unknown|   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|            unknown|   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|            unknown|   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|            unknown|   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|            unknown|   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|            unknown|   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|            unknown|   PR|     30100|\n|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|            unknown|   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/spark-examples/spark-scala-examples/master/src/main/resources/small_zipcode.csv\"\n",
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "df = spark.read.csv(\"file://\"+SparkFiles.get(\"small_zipcode.csv\"), header=True, inferSchema= True)\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "\n",
    "df.fillna(value=0).show()\n",
    "df.fillna(value=0,subset=[\"population\"]).show()\n",
    "df.na.fill(value=0).show()\n",
    "df.na.fill(value=0,subset=[\"population\"]).show()\n",
    "\n",
    "\n",
    "df.fillna(value=\"\").show()\n",
    "df.na.fill(value=\"\").show()\n",
    "\n",
    "df.fillna(\"unknown\",[\"city\"]) \\\n",
    "    .fillna(\"\",[\"type\"]).show()\n",
    "\n",
    "df.fillna({\"city\": \"unknown\", \"type\": \"\"}) \\\n",
    "    .show()\n",
    "\n",
    "df.na.fill(\"unknown\",[\"city\"]) \\\n",
    "    .na.fill(\"\",[\"type\"]).show()\n",
    "\n",
    "df.na.fill({\"city\": \"unknown\", \"type\": \"\"}) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b17ea1-e919-4925-a1cf-72efcbec5c9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Product: string (nullable = true)\n |-- Amount: long (nullable = true)\n |-- Country: string (nullable = true)\n\n+-------+------+-------+\n|Product|Amount|Country|\n+-------+------+-------+\n|Banana |1000  |USA    |\n|Carrots|1500  |USA    |\n|Beans  |1600  |USA    |\n|Orange |2000  |USA    |\n|Orange |2000  |USA    |\n|Banana |400   |China  |\n|Carrots|1200  |China  |\n|Beans  |1500  |China  |\n|Orange |4000  |China  |\n|Banana |2000  |Canada |\n|Carrots|2000  |Canada |\n|Beans  |2000  |Mexico |\n+-------+------+-------+\n\nroot\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\nroot\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\n+-------+-------+-----+\n|Product|Country|Total|\n+-------+-------+-----+\n|Orange |China  |4000 |\n|Beans  |China  |1500 |\n|Beans  |Mexico |2000 |\n|Banana |Canada |2000 |\n|Banana |China  |400  |\n|Carrots|Canada |2000 |\n|Carrots|China  |1200 |\n+-------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)\n",
    "\n",
    "pivotDF = df.groupBy(\"Product\",\"Country\") \\\n",
    "      .sum(\"Amount\") \\\n",
    "      .groupBy(\"Product\") \\\n",
    "      .pivot(\"Country\") \\\n",
    "      .sum(\"sum(Amount)\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)\n",
    "\n",
    "\"\"\" unpivot \"\"\"\n",
    "unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
    "unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
    "    .where(\"Total is not null\")\n",
    "unPivotDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ccaa748-e5d7-43db-9301-07799ec2890f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. DataFrame",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
